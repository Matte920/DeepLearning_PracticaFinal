{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs0qPTz4hPHARGx2SdzD44",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matte920/DeepLearning_PracticaFinal/blob/main/Hito3_LateFusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e--B2UJedZTK",
        "outputId": "88ff70d3-b71f-4ac8-d65a-749cdc7a6c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape metadata: (10015, 7)\n",
            "Shape imágenes: (10015, 2352)\n",
            "Num. píxeles por imagen: 2352\n",
            "Shape X_img (después reshape): (10015, 28, 28, 3)\n",
            "Shape X_train_tab: (8012, 19)\n",
            "Shape X_train_img: (8012, 28, 28, 3)\n",
            "Shape y_train: (8012, 7)\n",
            "Epoch 1/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4549 - loss: 1.6141 - val_accuracy: 0.6862 - val_loss: 0.9692\n",
            "Epoch 2/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6803 - loss: 1.0484 - val_accuracy: 0.7018 - val_loss: 0.9241\n",
            "Epoch 3/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 1.0072 - val_accuracy: 0.7018 - val_loss: 0.9051\n",
            "Epoch 4/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6890 - loss: 1.0035 - val_accuracy: 0.6987 - val_loss: 0.8976\n",
            "Epoch 5/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6886 - loss: 0.9887 - val_accuracy: 0.6993 - val_loss: 0.8948\n",
            "Epoch 6/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7000 - loss: 0.9554 - val_accuracy: 0.6981 - val_loss: 0.8925\n",
            "Epoch 7/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7022 - loss: 0.9469 - val_accuracy: 0.6974 - val_loss: 0.8904\n",
            "Epoch 8/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6866 - loss: 0.9665 - val_accuracy: 0.7024 - val_loss: 0.8876\n",
            "Epoch 9/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7020 - loss: 0.9385 - val_accuracy: 0.6981 - val_loss: 0.8865\n",
            "Epoch 10/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6962 - loss: 0.9360 - val_accuracy: 0.6981 - val_loss: 0.8841\n",
            "Test accuracy modelo 1D (tabular): 0.6969545483589172\n",
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - accuracy: 0.6126 - loss: 1.2899 - val_accuracy: 0.6781 - val_loss: 1.0024\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 169ms/step - accuracy: 0.6634 - loss: 1.0490 - val_accuracy: 0.6787 - val_loss: 0.9078\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 168ms/step - accuracy: 0.6705 - loss: 0.9732 - val_accuracy: 0.6769 - val_loss: 0.8634\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - accuracy: 0.6692 - loss: 0.9342 - val_accuracy: 0.6831 - val_loss: 0.8522\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.6605 - loss: 0.9408 - val_accuracy: 0.6806 - val_loss: 0.8175\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 145ms/step - accuracy: 0.6834 - loss: 0.8706 - val_accuracy: 0.6887 - val_loss: 0.8062\n",
            "Epoch 7/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - accuracy: 0.6879 - loss: 0.8323 - val_accuracy: 0.6981 - val_loss: 0.7869\n",
            "Epoch 8/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - accuracy: 0.7003 - loss: 0.7867 - val_accuracy: 0.7162 - val_loss: 0.7909\n",
            "Epoch 9/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7019 - loss: 0.8139 - val_accuracy: 0.7124 - val_loss: 0.7346\n",
            "Epoch 10/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - accuracy: 0.7098 - loss: 0.7773 - val_accuracy: 0.7361 - val_loss: 0.7622\n",
            "Test accuracy modelo 2D (imágenes): 0.7234148979187012\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Shape pred_tab_train: (8012, 7)\n",
            "Shape pred_img_train: (8012, 7)\n",
            "Shape Z_train (late-fusion): (8012, 14)\n",
            "Epoch 1/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2203 - loss: 1.9649 - val_accuracy: 0.6781 - val_loss: 1.2620\n",
            "Epoch 2/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6654 - loss: 1.1804 - val_accuracy: 0.6925 - val_loss: 0.9142\n",
            "Epoch 3/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6841 - loss: 0.9526 - val_accuracy: 0.7105 - val_loss: 0.8232\n",
            "Epoch 4/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7080 - loss: 0.8768 - val_accuracy: 0.7199 - val_loss: 0.7843\n",
            "Epoch 5/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7156 - loss: 0.8351 - val_accuracy: 0.7199 - val_loss: 0.7621\n",
            "Epoch 6/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7184 - loss: 0.8093 - val_accuracy: 0.7199 - val_loss: 0.7461\n",
            "Epoch 7/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7141 - loss: 0.8100 - val_accuracy: 0.7205 - val_loss: 0.7335\n",
            "Epoch 8/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.7731 - val_accuracy: 0.7224 - val_loss: 0.7223\n",
            "Epoch 9/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7320 - loss: 0.7607 - val_accuracy: 0.7249 - val_loss: 0.7126\n",
            "Epoch 10/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7195 - loss: 0.7745 - val_accuracy: 0.7374 - val_loss: 0.7047\n",
            "Test accuracy (estrategia LATE-FUSION – HITO 3): 0.7289066314697266\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "df_meta = pd.read_csv(\"/content/HAM10000_metadata.csv\")\n",
        "\n",
        "df_img = pd.read_csv(\"/content/hnmist_28_28_RGB.csv\")\n",
        "\n",
        "print(\"Shape metadata:\", df_meta.shape)\n",
        "print(\"Shape imágenes:\", df_img.shape)\n",
        "\n",
        "\n",
        "\n",
        "y_str = df_meta[\"dx\"].values\n",
        "le = LabelEncoder()\n",
        "y_int = le.fit_transform(y_str)\n",
        "num_classes = len(le.classes_)\n",
        "y_oh = keras.utils.to_categorical(y_int, num_classes=num_classes)\n",
        "\n",
        "\n",
        "\n",
        "X_tab = df_meta[[\"sex\", \"age\", \"localization\"]].copy()\n",
        "\n",
        "X_tab[\"sex\"] = X_tab[\"sex\"].fillna(\"unknown\")\n",
        "X_tab[\"localization\"] = X_tab[\"localization\"].fillna(\"unknown\")\n",
        "X_tab[\"age\"] = X_tab[\"age\"].fillna(X_tab[\"age\"].median())\n",
        "\n",
        "\n",
        "X_tab = pd.get_dummies(X_tab, columns=[\"sex\", \"localization\"])\n",
        "\n",
        "X_tab = X_tab.astype(\"float32\")\n",
        "\n",
        "\n",
        "input_dim_tab = X_tab.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "X_img = df_img.values.astype(\"float32\")\n",
        "\n",
        "\n",
        "X_img = X_img / 255.0\n",
        "\n",
        "num_pixels = X_img.shape[1]\n",
        "print(\"Num. píxeles por imagen:\", num_pixels)\n",
        "\n",
        "assert num_pixels == 28 * 28 * 3, \"Número de píxeles inesperado.\"\n",
        "\n",
        "\n",
        "X_img = X_img.reshape(-1, 28, 28, 3)\n",
        "input_shape_img = (28, 28, 3)\n",
        "\n",
        "print(\"Shape X_img (después reshape):\", X_img.shape)\n",
        "\n",
        "\n",
        "indices = np.arange(len(y_int))\n",
        "\n",
        "idx_train, idx_test = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_int\n",
        ")\n",
        "\n",
        "X_train_tab = X_tab.values[idx_train]\n",
        "X_test_tab  = X_tab.values[idx_test]\n",
        "\n",
        "X_train_img = X_img[idx_train]\n",
        "X_test_img  = X_img[idx_test]\n",
        "\n",
        "y_train = y_oh[idx_train]\n",
        "y_test  = y_oh[idx_test]\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_tab[:, 0:1] = scaler.fit_transform(X_train_tab[:, 0:1])\n",
        "X_test_tab[:, 0:1] = scaler.transform(X_test_tab[:, 0:1])\n",
        "\n",
        "print(\"Shape X_train_tab:\", X_train_tab.shape)\n",
        "print(\"Shape X_train_img:\", X_train_img.shape)\n",
        "print(\"Shape y_train:\", y_train.shape)\n",
        "\n",
        "\n",
        "input_tab = keras.Input(shape=(input_dim_tab,), name=\"tabular_input\")\n",
        "\n",
        "t = layers.Dense(64, activation=\"relu\")(input_tab)\n",
        "t = layers.Dropout(0.3)(t)\n",
        "t = layers.Dense(32, activation=\"relu\")(t)\n",
        "t = layers.Dropout(0.3)(t)\n",
        "out_tab = layers.Dense(num_classes, activation=\"softmax\", name=\"tabular_output\")(t)\n",
        "\n",
        "model_tab = keras.Model(inputs=input_tab, outputs=out_tab, name=\"modelo_1D_tabular\")\n",
        "\n",
        "model_tab.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_tab = model_tab.fit(\n",
        "    X_train_tab,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss_tab_test, acc_tab_test = model_tab.evaluate(X_test_tab, y_test, verbose=0)\n",
        "print(\"Test accuracy modelo 1D (tabular):\", acc_tab_test)\n",
        "\n",
        "\n",
        "\n",
        "input_img = keras.Input(shape=input_shape_img, name=\"imagen_input\")\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "out_img = layers.Dense(num_classes, activation=\"softmax\", name=\"imagen_output\")(x)\n",
        "\n",
        "model_2d = keras.Model(inputs=input_img, outputs=out_img, name=\"modelo_2D_imagenes\")\n",
        "\n",
        "model_2d.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_2d = model_2d.fit(\n",
        "    X_train_img,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss_img_test, acc_img_test = model_2d.evaluate(X_test_img, y_test, verbose=0)\n",
        "print(\"Test accuracy modelo 2D (imágenes):\", acc_img_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pred_tab_train = model_tab.predict(X_train_tab)\n",
        "pred_tab_test  = model_tab.predict(X_test_tab)\n",
        "\n",
        "pred_img_train = model_2d.predict(X_train_img)\n",
        "pred_img_test  = model_2d.predict(X_test_img)\n",
        "\n",
        "print(\"Shape pred_tab_train:\", pred_tab_train.shape)\n",
        "print(\"Shape pred_img_train:\", pred_img_train.shape)\n",
        "\n",
        "\n",
        "Z_train = np.concatenate([pred_tab_train, pred_img_train], axis=1)\n",
        "Z_test  = np.concatenate([pred_tab_test,  pred_img_test],  axis=1)\n",
        "\n",
        "print(\"Shape Z_train (late-fusion):\", Z_train.shape)\n",
        "\n",
        "\n",
        "input_fusion = keras.Input(shape=(2 * num_classes,), name=\"fusion_input\")\n",
        "\n",
        "f = layers.Dense(32, activation=\"relu\")(input_fusion)\n",
        "f = layers.Dropout(0.3)(f)\n",
        "out_fusion = layers.Dense(num_classes, activation=\"softmax\", name=\"fusion_output\")(f)\n",
        "\n",
        "model_fusion = keras.Model(inputs=input_fusion, outputs=out_fusion, name=\"modelo_late_fusion\")\n",
        "\n",
        "model_fusion.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_fusion = model_fusion.fit(\n",
        "    Z_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss_fusion_test, acc_fusion_test = model_fusion.evaluate(Z_test, y_test, verbose=0)\n",
        "print(\"Test accuracy (estrategia LATE-FUSION – HITO 3):\", acc_fusion_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo que combina las predicciones 1D y 2D obtiene una accuracy ≈0.68.\n",
        "Confirma que fusionar ambas fuentes mejora respecto al modelo tabular."
      ],
      "metadata": {
        "id": "u--U0EKQfVxR"
      }
    }
  ]
}