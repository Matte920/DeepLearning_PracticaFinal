{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e--B2UJedZTK",
        "outputId": "9069ba8f-fc31-409e-8609-32312b347ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape metadata: (10015, 7)\n",
            "Shape imágenes: (10015, 2352)\n",
            "Num. píxeles por imagen: 2352\n",
            "Shape X_img (después reshape): (10015, 28, 28, 3)\n",
            "Shape X_train_tab: (8012, 19)\n",
            "Shape X_train_img: (8012, 28, 28, 3)\n",
            "Shape y_train: (8012, 7)\n",
            "Epoch 1/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5667 - loss: 1.4929 - val_accuracy: 0.6787 - val_loss: 0.9688\n",
            "Epoch 2/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6664 - loss: 1.0656 - val_accuracy: 0.6968 - val_loss: 0.9142\n",
            "Epoch 3/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6899 - loss: 1.0038 - val_accuracy: 0.6999 - val_loss: 0.9004\n",
            "Epoch 4/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6838 - loss: 1.0051 - val_accuracy: 0.6974 - val_loss: 0.8934\n",
            "Epoch 5/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6989 - loss: 0.9624 - val_accuracy: 0.7018 - val_loss: 0.8890\n",
            "Epoch 6/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6945 - loss: 0.9664 - val_accuracy: 0.7012 - val_loss: 0.8891\n",
            "Epoch 7/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6930 - loss: 0.9581 - val_accuracy: 0.7012 - val_loss: 0.8846\n",
            "Epoch 8/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6946 - loss: 0.9544 - val_accuracy: 0.7031 - val_loss: 0.8827\n",
            "Epoch 9/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7025 - loss: 0.9381 - val_accuracy: 0.6981 - val_loss: 0.8853\n",
            "Epoch 10/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6986 - loss: 0.9366 - val_accuracy: 0.7012 - val_loss: 0.8819\n",
            "Test accuracy modelo 1D (tabular): 0.6984522938728333\n",
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 267ms/step - accuracy: 0.6225 - loss: 1.2785 - val_accuracy: 0.6781 - val_loss: 1.0080\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.6685 - loss: 1.0437 - val_accuracy: 0.6812 - val_loss: 0.9130\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - accuracy: 0.6687 - loss: 0.9719 - val_accuracy: 0.6837 - val_loss: 0.8539\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - accuracy: 0.6695 - loss: 0.9189 - val_accuracy: 0.6868 - val_loss: 0.8377\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - accuracy: 0.6808 - loss: 0.8756 - val_accuracy: 0.6856 - val_loss: 0.8394\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - accuracy: 0.6859 - loss: 0.8523 - val_accuracy: 0.7105 - val_loss: 0.8098\n",
            "Epoch 7/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - accuracy: 0.6973 - loss: 0.8245 - val_accuracy: 0.6999 - val_loss: 0.7953\n",
            "Epoch 8/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.7028 - loss: 0.8137 - val_accuracy: 0.7112 - val_loss: 0.7443\n",
            "Epoch 9/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 177ms/step - accuracy: 0.7093 - loss: 0.7744 - val_accuracy: 0.7249 - val_loss: 0.7513\n",
            "Epoch 10/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 167ms/step - accuracy: 0.7082 - loss: 0.7940 - val_accuracy: 0.6987 - val_loss: 0.7678\n",
            "Test accuracy modelo 2D (imágenes): 0.6909635663032532\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Shape pred_tab_train: (8012, 7)\n",
            "Shape pred_img_train: (8012, 7)\n",
            "Shape Z_train (late-fusion): (8012, 14)\n",
            "Epoch 1/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4284 - loss: 1.7050 - val_accuracy: 0.6781 - val_loss: 1.1353\n",
            "Epoch 2/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6842 - loss: 1.0612 - val_accuracy: 0.6999 - val_loss: 0.8739\n",
            "Epoch 3/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7089 - loss: 0.8908 - val_accuracy: 0.7199 - val_loss: 0.8057\n",
            "Epoch 4/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7156 - loss: 0.8479 - val_accuracy: 0.7218 - val_loss: 0.7807\n",
            "Epoch 5/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7208 - loss: 0.8367 - val_accuracy: 0.7311 - val_loss: 0.7602\n",
            "Epoch 6/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7265 - loss: 0.8096 - val_accuracy: 0.7374 - val_loss: 0.7447\n",
            "Epoch 7/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7335 - loss: 0.7903 - val_accuracy: 0.7511 - val_loss: 0.7306\n",
            "Epoch 8/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.7609 - val_accuracy: 0.7598 - val_loss: 0.7179\n",
            "Epoch 9/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.7666 - val_accuracy: 0.7623 - val_loss: 0.7090\n",
            "Epoch 10/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.7482 - val_accuracy: 0.7580 - val_loss: 0.7017\n",
            "Test accuracy (estrategia LATE-FUSION – HITO 3): 0.7413879036903381\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "df_meta = pd.read_csv(\"/content/HAM10000_metadata.csv\")\n",
        "\n",
        "df_img = pd.read_csv(\"/content/hnmist_28_28_RGB.csv\")\n",
        "\n",
        "print(\"Shape metadata:\", df_meta.shape)\n",
        "print(\"Shape imágenes:\", df_img.shape)\n",
        "\n",
        "\n",
        "\n",
        "y_str = df_meta[\"dx\"].values\n",
        "le = LabelEncoder()\n",
        "y_int = le.fit_transform(y_str)\n",
        "num_classes = len(le.classes_)\n",
        "y_oh = keras.utils.to_categorical(y_int, num_classes=num_classes)\n",
        "\n",
        "\n",
        "\n",
        "X_tab = df_meta[[\"sex\", \"age\", \"localization\"]].copy()\n",
        "\n",
        "X_tab[\"sex\"] = X_tab[\"sex\"].fillna(\"unknown\")\n",
        "X_tab[\"localization\"] = X_tab[\"localization\"].fillna(\"unknown\")\n",
        "X_tab[\"age\"] = X_tab[\"age\"].fillna(X_tab[\"age\"].median())\n",
        "\n",
        "\n",
        "X_tab = pd.get_dummies(X_tab, columns=[\"sex\", \"localization\"])\n",
        "\n",
        "X_tab = X_tab.astype(\"float32\")\n",
        "\n",
        "\n",
        "input_dim_tab = X_tab.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "X_img = df_img.values.astype(\"float32\")\n",
        "\n",
        "\n",
        "X_img = X_img / 255.0\n",
        "\n",
        "num_pixels = X_img.shape[1]\n",
        "print(\"Num. píxeles por imagen:\", num_pixels)\n",
        "\n",
        "assert num_pixels == 28 * 28 * 3, \"Número de píxeles inesperado.\"\n",
        "\n",
        "\n",
        "X_img = X_img.reshape(-1, 28, 28, 3)\n",
        "input_shape_img = (28, 28, 3)\n",
        "\n",
        "print(\"Shape X_img (después reshape):\", X_img.shape)\n",
        "\n",
        "\n",
        "indices = np.arange(len(y_int))\n",
        "\n",
        "idx_train, idx_test = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_int\n",
        ")\n",
        "\n",
        "X_train_tab = X_tab.values[idx_train]\n",
        "X_test_tab  = X_tab.values[idx_test]\n",
        "\n",
        "X_train_img = X_img[idx_train]\n",
        "X_test_img  = X_img[idx_test]\n",
        "\n",
        "y_train = y_oh[idx_train]\n",
        "y_test  = y_oh[idx_test]\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_tab[:, 0:1] = scaler.fit_transform(X_train_tab[:, 0:1])\n",
        "X_test_tab[:, 0:1] = scaler.transform(X_test_tab[:, 0:1])\n",
        "\n",
        "print(\"Shape X_train_tab:\", X_train_tab.shape)\n",
        "print(\"Shape X_train_img:\", X_train_img.shape)\n",
        "print(\"Shape y_train:\", y_train.shape)\n",
        "\n",
        "\n",
        "input_tab = keras.Input(shape=(input_dim_tab,), name=\"tabular_input\")\n",
        "\n",
        "t = layers.Dense(64, activation=\"relu\")(input_tab)\n",
        "t = layers.Dropout(0.3)(t)\n",
        "t = layers.Dense(32, activation=\"relu\")(t)\n",
        "t = layers.Dropout(0.3)(t)\n",
        "out_tab = layers.Dense(num_classes, activation=\"softmax\", name=\"tabular_output\")(t)\n",
        "\n",
        "model_tab = keras.Model(inputs=input_tab, outputs=out_tab, name=\"modelo_1D_tabular\")\n",
        "\n",
        "model_tab.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_tab = model_tab.fit(\n",
        "    X_train_tab,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss_tab_test, acc_tab_test = model_tab.evaluate(X_test_tab, y_test, verbose=0)\n",
        "print(\"Test accuracy modelo 1D (tabular):\", acc_tab_test)\n",
        "\n",
        "\n",
        "\n",
        "input_img = keras.Input(shape=input_shape_img, name=\"imagen_input\")\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "out_img = layers.Dense(num_classes, activation=\"softmax\", name=\"imagen_output\")(x)\n",
        "\n",
        "model_2d = keras.Model(inputs=input_img, outputs=out_img, name=\"modelo_2D_imagenes\")\n",
        "\n",
        "model_2d.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_2d = model_2d.fit(\n",
        "    X_train_img,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss_img_test, acc_img_test = model_2d.evaluate(X_test_img, y_test, verbose=0)\n",
        "print(\"Test accuracy modelo 2D (imágenes):\", acc_img_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pred_tab_train = model_tab.predict(X_train_tab)\n",
        "pred_tab_test  = model_tab.predict(X_test_tab)\n",
        "\n",
        "pred_img_train = model_2d.predict(X_train_img)\n",
        "pred_img_test  = model_2d.predict(X_test_img)\n",
        "\n",
        "print(\"Shape pred_tab_train:\", pred_tab_train.shape)\n",
        "print(\"Shape pred_img_train:\", pred_img_train.shape)\n",
        "\n",
        "\n",
        "Z_train = np.concatenate([pred_tab_train, pred_img_train], axis=1)\n",
        "Z_test  = np.concatenate([pred_tab_test,  pred_img_test],  axis=1)\n",
        "\n",
        "print(\"Shape Z_train (late-fusion):\", Z_train.shape)\n",
        "\n",
        "\n",
        "input_fusion = keras.Input(shape=(2 * num_classes,), name=\"fusion_input\")\n",
        "\n",
        "f = layers.Dense(32, activation=\"relu\")(input_fusion)\n",
        "f = layers.Dropout(0.3)(f)\n",
        "out_fusion = layers.Dense(num_classes, activation=\"softmax\", name=\"fusion_output\")(f)\n",
        "\n",
        "model_fusion = keras.Model(inputs=input_fusion, outputs=out_fusion, name=\"modelo_late_fusion\")\n",
        "\n",
        "model_fusion.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_fusion = model_fusion.fit(\n",
        "    Z_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss_fusion_test, acc_fusion_test = model_fusion.evaluate(Z_test, y_test, verbose=0)\n",
        "print(\"Test accuracy (estrategia LATE-FUSION – HITO 3):\", acc_fusion_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo que combina las predicciones 1D y 2D obtiene una accuracy ≈0.68.\n",
        "Confirma que fusionar ambas fuentes mejora respecto al modelo tabular."
      ],
      "metadata": {
        "id": "u--U0EKQfVxR"
      }
    }
  ]
}